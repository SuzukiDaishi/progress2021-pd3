# 研究ワークシート

## テーマ
**リアルタイム Any-to-One 音声変換**

### リアルタイムの定義
遅延が100ms以下
マイク入力から音声出力までの時間

### Any-to-oneの定義
学習済み及び未学習の話者の声質(スペクトル包絡またはMCEPs)を特定の話者の声質に変換できること

## なぜ自分の手法で高速化ができるのか
1. 現在の手法ではメルスペクトログラム変換後、波形に戻す必要がある。  
その際にWavenetなどの低速な手法でそれを行うためリアルタイムは不可能。
2. その工程をなくすために学習でMCEPsを用い、波形に戻す際もWorldを用いるためかなりの高速化が可能であると考える。

## どこに新規性があるのか
- AutoVCの学習にメルスペクトログラムではなくMCEPsを用いることで、  
高速化ができる。
- ピッチ情報を別にすることでピッチの変換が苦手な問題を解消できる。

## 現在の進捗
1. AutoVCの日本語化
   - 岩沢さん: 日本語化は必要か
2. AutoVCが本当に論文通りのことができるのか検証

## 実装
- https://github.com/peisuke/AutoVC.pytorch
- https://github.com/auspicious3000/autovc
  - こっちが本家

## 読む
- https://arxiv.org/abs/1905.05879
- https://arxiv.org/abs/2004.07370
- https://arxiv.org/abs/2004.11284

## 中沢先生からのアドバイス
- 電話 -> 50ms以内のやり取り
- オンラインで100msの場合止まってるイメージ

- どの程度のながさなら50ms以下で返せる、100ms以下で返せる。
- 特定の条件下で50ms以下でもOK

- AutoVCの論文についてまとめる(落合めそっど)